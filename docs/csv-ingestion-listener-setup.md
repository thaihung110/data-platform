# H∆∞·ªõng D·∫´n C·∫•u H√¨nh Airflow cho CSV Ingestion Listener

## T·ªïng Quan

DAG `csv-ingestion-listener` l·∫Øng nghe Kafka topic `csv-ingestion` v√† trigger NiFi process group ƒë·ªÉ x·ª≠ l√Ω CSV chunks ƒë∆∞·ª£c upload l√™n source-api.

## Y√™u C·∫ßu

1. Airflow ƒë√£ ƒë∆∞·ª£c deploy l√™n Kubernetes
2. Airflow provider packages:
   - `apache-airflow-providers-apache-kafka`
   - `apache-airflow-providers-http`
3. Kafka cluster ƒëang ch·∫°y v·ªõi SASL authentication
4. NiFi cluster ƒëang ch·∫°y

---

## B∆∞·ªõc 1: T·∫°o Airflow Connections

### 1.1. Kafka Connection

**Truy c·∫≠p Airflow UI:**

1. ƒêƒÉng nh·∫≠p v√†o Airflow web UI
2. V√†o **Admin** ‚Üí **Connections**
3. Click **+** (Add a new record)

**C·∫•u h√¨nh:**

| Field           | Value                 |
| --------------- | --------------------- |
| Connection Id   | `kafka_csv_ingestion` |
| Connection Type | `Kafka`               |
| Host            | `openhouse-kafka`     |
| Port            | `9092`                |
| Extra           | (Xem JSON b√™n d∆∞·ªõi)   |

**Extra JSON:**

```json
{
  "bootstrap.servers": "openhouse-kafka:9092",
  "security.protocol": "SASL_PLAINTEXT",
  "sasl.mechanism": "PLAIN",
  "sasl.username": "admin",
  "sasl.password": "admin",
  "group.id": "airflow-csv-ingestion-consumer",
  "auto.offset.reset": "latest",
  "enable.auto.commit": true,
  "session.timeout.ms": 30000
}
```

**Gi·∫£i th√≠ch:**

- `bootstrap.servers`: ƒê·ªãa ch·ªâ Kafka broker trong cluster
- `security.protocol`: SASL_PLAINTEXT (SASL auth kh√¥ng d√πng TLS)
- `sasl.mechanism`: PLAIN (username/password authentication)
- `sasl.username/password`: Credentials ƒë·ªÉ connect v√†o Kafka
- `group.id`: Consumer group ID ƒë·ªÉ track offset
- `auto.offset.reset`: `latest` - ch·ªâ consume messages m·ªõi, kh√¥ng process messages c≈©

---

### 1.2. NiFi HTTP Connection

**C·∫•u h√¨nh:**

| Field           | Value                    |
| --------------- | ------------------------ |
| Connection Id   | `nifi_rest_api`          |
| Connection Type | `HTTP`                   |
| Host            | `https://openhouse-nifi` |
| Port            | `8443`                   |
| Extra           | (Xem JSON b√™n d∆∞·ªõi)      |

**Extra JSON (Option 1: No Authentication):**

```json
{
  "verify": false
}
```

**Extra JSON (Option 2: With Basic Auth):**

```json
{
  "verify": false,
  "auth": ["nifi_username", "nifi_password"]
}
```

**Extra JSON (Option 3: With Token Auth):**

```json
{
  "verify": false,
  "headers": {
    "Authorization": "Bearer YOUR_NIFI_TOKEN"
  }
}
```

> **L∆∞u √Ω:**
>
> - `verify: false` ƒë·ªÉ b·ªè qua SSL certificate validation (ch·ªâ d√πng trong dev/test)
> - Trong production, n√™n set `verify: true` v√† cung c·∫•p CA certificate

---

## B∆∞·ªõc 2: T·∫°o Airflow Variable

**Truy c·∫≠p Airflow UI:**

1. V√†o **Admin** ‚Üí **Variables**
2. Click **+** (Add a new record)

**C·∫•u h√¨nh:**

| Key                     | Value                                  |
| ----------------------- | -------------------------------------- |
| `nifi_process_group_id` | `4be3c5be-019b-1000-4ef1-949cbb8c08de` |

**Gi·∫£i th√≠ch:**

- Bi·∫øn n√†y l∆∞u ID c·ªßa NiFi process group c·∫ßn trigger
- DAG s·∫Ω ƒë·ªçc gi√° tr·ªã n√†y khi c·∫ßn trigger NiFi

---

## B∆∞·ªõc 3: Test Connections

### 3.1. Test Kafka Connection

**T·ª´ Airflow Scheduler Pod:**

```bash
# Exec v√†o scheduler pod
kubectl exec -it <airflow-scheduler-pod-name> -- bash

# Test connection
airflow connections test kafka_csv_ingestion
```

**Expected Output:**

```
Connection successfully tested
```

**N·∫øu g·∫∑p l·ªói:**

- Verify Kafka service ƒëang ch·∫°y: `kubectl get svc | grep kafka`
- Check SASL credentials trong connection Extra
- Verify network policy cho ph√©p Airflow connect t·ªõi Kafka

---

### 3.2. Test NiFi Connection

**T·ª´ Airflow Scheduler Pod:**

```bash
# Test connection
airflow connections test nifi_rest_api

# Ho·∫∑c test b·∫±ng curl
curl -k https://openhouse-nifi:8443/nifi-api/system-diagnostics
```

**Expected Output:**

```
Connection successfully tested
```

Ho·∫∑c JSON response t·ª´ NiFi API

**N·∫øu g·∫∑p l·ªói:**

- Verify NiFi service: `kubectl get svc | grep nifi`
- Check NiFi authentication n·∫øu c√≥ b·∫≠t
- Verify network policy

---

### 3.3. Test Kafka Message Consumption

**T·ª´ Kafka Pod:**

```bash
# Exec v√†o Kafka pod
kubectl exec -it openhouse-kafka-0 -- bash

# Consume messages t·ª´ topic
kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic csv-ingestion \
  --from-beginning \
  --consumer-property security.protocol=SASL_PLAINTEXT \
  --consumer-property sasl.mechanism=PLAIN \
  --consumer-property sasl.jaas.config='org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin";'
```

**Ki·ªÉm tra:**

- C√≥ messages hi·ªÉn th·ªã kh√¥ng?
- Message format c√≥ ƒë√∫ng nh∆∞ expected kh√¥ng?

---

## B∆∞·ªõc 4: Deploy & Enable DAG

### 4.1. Copy DAG File

**N·∫øu d√πng Git-Sync:**

```bash
# DAG file ƒë√£ ·ªü trong: airflow/dags/csv_ingestion_listener_dag.py
# Git-sync s·∫Ω t·ª± ƒë·ªông sync t·ª´ git repo
```

**N·∫øu d√πng PVC mount:**

```bash
# Copy file v√†o Airflow DAGs folder
kubectl cp airflow/dags/csv_ingestion_listener_dag.py \
  <airflow-scheduler-pod>:/opt/airflow/dags/
```

### 4.2. Verify DAG Appears

**T·ª´ Airflow UI:**

1. V√†o **DAGs** page
2. T√¨m DAG: `csv-ingestion-listener`
3. Verify DAG kh√¥ng c√≥ errors

**Ho·∫∑c t·ª´ CLI:**

```bash
kubectl exec -it <airflow-scheduler-pod> -- \
  airflow dags list | grep csv-ingestion-listener
```

### 4.3. Test DAG Syntax

```bash
kubectl exec -it <airflow-scheduler-pod> -- bash

# Test DAG import
python /opt/airflow/dags/csv_ingestion_listener_dag.py

# List tasks trong DAG
airflow dags show csv-ingestion-listener

# Test specific task
airflow tasks test csv-ingestion-listener listen_kafka_csv_topic 2025-12-26
```

---

## B∆∞·ªõc 5: End-to-End Testing

### 5.1. Upload CSV File

```bash
# Upload CSV file qua source-api
curl -X POST http://localhost:8000/api/v1/upload/csv \
  -F "file=@taxi.csv" \
  -F "dataset_name=taxi_test" \
  -F "chunk_type=rows" \
  -F "chunk_rows=100"
```

**Expected:**

- Source-api s·∫Ω publish messages t·ªõi Kafka topic `csv-ingestion`
- M·ªói chunk s·∫Ω l√† 1 message

### 5.2. Monitor Airflow DAG

**Trong Airflow UI:**

1. DAG `csv-ingestion-listener` s·∫Ω t·ª± ƒë·ªông trigger (n·∫øu enabled)
2. Theo d√µi task execution:
   - `listen_kafka_csv_topic` - ƒêang l·∫Øng nghe Kafka
   - `extract_message_data` - Extract message
   - `trigger_nifi_process_group` - Trigger NiFi

**Xem Logs:**

- Click v√†o m·ªói task ‚Üí **Log**
- Verify message ƒë∆∞·ª£c nh·∫≠n v√† validate ƒë√∫ng
- Check NiFi trigger response

### 5.3. Verify NiFi Processing

**Trong NiFi UI:**

1. Truy c·∫≠p process group: `4be3c5be-019b-1000-4ef1-949cbb8c08de`
2. Verify processors ƒëang ch·∫°y (state: RUNNING)
3. Check data flow qua c√°c processors
4. Verify output (files trong MinIO, data trong database, etc.)

---

## Troubleshooting

### Issue 1: DAG Kh√¥ng Trigger

**Tri·ªáu ch·ª©ng:**

- DAG appears trong UI nh∆∞ng kh√¥ng trigger khi c√≥ message

**Gi·∫£i quy·∫øt:**

1. Enable DAG trong UI (toggle switch)
2. Check DAG schedule: `schedule_interval=None` l√† event-driven
3. Manually trigger: Click **‚ñ∂ Trigger DAG**
4. Check Airflow scheduler logs:
   ```bash
   kubectl logs <airflow-scheduler-pod> | grep csv-ingestion
   ```

---

### Issue 2: Kafka Connection Failed

**Tri·ªáu ch·ª©ng:**

```
Connection refused / Authentication failed
```

**Gi·∫£i quy·∫øt:**

1. Verify Kafka service DNS:

   ```bash
   kubectl get svc openhouse-kafka
   nslookup openhouse-kafka
   ```

2. Test network connectivity:

   ```bash
   kubectl exec -it <airflow-scheduler-pod> -- \
     nc -zv openhouse-kafka 9092
   ```

3. Verify SASL credentials:

   ```bash
   # Get Kafka SASL password from secret
   kubectl get secret <kafka-secret-name> -o jsonpath='{.data.client-passwords}' | base64 -d
   ```

4. Check Kafka listener configuration:
   ```bash
   kubectl exec -it openhouse-kafka-0 -- \
     cat /opt/bitnami/kafka/config/server.properties | grep listener
   ```

---

### Issue 3: NiFi Trigger Failed

**Tri·ªáu ch·ª©ng:**

```
Failed to trigger NiFi PG. Status: 401/403/404
```

**Gi·∫£i quy·∫øt:**

**Status 401/403 (Unauthorized/Forbidden):**

- NiFi requires authentication
- Update connection v·ªõi username/password ho·∫∑c token
- Check NiFi user permissions

**Status 404 (Not Found):**

- Process group ID kh√¥ng t·ªìn t·∫°i
- Verify ID trong NiFi UI:
  1. Right-click process group ‚Üí Configure
  2. Check ID trong Settings tab
- Update Airflow Variable `nifi_process_group_id`

**Status 500 (Internal Server Error):**

- Check NiFi logs:
  ```bash
  kubectl logs <nifi-pod> | grep ERROR
  ```

---

### Issue 4: Message Format Invalid

**Tri·ªáu ch·ª©ng:**

```
Invalid message - missing fields: [...]
```

**Gi·∫£i quy·∫øt:**

1. Check message format t·ª´ source-api
2. Verify required fields trong DAG code
3. Update `listen_for_csv_messages` function n·∫øu c·∫ßn

---

## Monitoring & Maintenance

### Monitor DAG Execution

**Airflow Metrics:**

- DAG run success rate
- Task duration
- Failed tasks count

**Kafka Metrics:**

- Consumer lag: S·ªë messages ch∆∞a ƒë∆∞·ª£c consume
- Message processing rate

```bash
# Check consumer group lag
kubectl exec -it openhouse-kafka-0 -- \
  kafka-consumer-groups.sh \
    --bootstrap-server localhost:9092 \
    --describe \
    --group airflow-csv-ingestion-consumer \
    --command-config /opt/bitnami/kafka/config/consumer.properties
```

### Log Locations

**Airflow Logs:**

- Scheduler: `kubectl logs <airflow-scheduler-pod>`
- Task logs: Airflow UI ‚Üí DAG ‚Üí Task ‚Üí Log

**Kafka Logs:**

- `kubectl logs <kafka-pod>`

**NiFi Logs:**

- `kubectl logs <nifi-pod>`
- NiFi UI ‚Üí Summary ‚Üí View System Diagnostics ‚Üí Logs

---

## Advanced Configuration

### Parallel Message Processing

DAG configuration cho ph√©p x·ª≠ l√Ω nhi·ªÅu messages ƒë·ªìng th·ªùi:

```python
max_active_runs=5  # Cho ph√©p 5 DAG runs c√πng l√∫c
```

**L∆∞u √Ω:**

- TƒÉng `max_active_runs` n·∫øu c√≥ nhi·ªÅu CSV uploads ƒë·ªìng th·ªùi
- Monitor Airflow worker resources (CPU, memory)

### Custom Consumer Group

Thay ƒë·ªïi `group.id` trong Kafka connection n·∫øu mu·ªën:

- Reset offset v√† consume l·∫°i t·ª´ ƒë·∫ßu
- T·∫°o multiple consumers cho c√πng topic

### Retry Strategy

DAG configuration:

```python
"retries": 3,
"retry_delay": timedelta(minutes=2),
```

ƒêi·ªÅu ch·ªânh t√πy theo:

- Network reliability
- NiFi availability
- Business requirements

---

## Security Best Practices

### 1. Kafka Authentication

‚úÖ **ƒêang l√†m:**

- SASL_PLAINTEXT with username/password

‚ö†Ô∏è **N√™n c·∫£i thi·ªán:**

- S·ª≠ d·ª•ng SASL_SSL thay v√¨ SASL_PLAINTEXT (encrypt credentials)
- Rotate passwords ƒë·ªãnh k·ª≥
- S·ª≠ d·ª•ng SCRAM-SHA-256/512 thay v√¨ PLAIN

### 2. NiFi Authentication

‚ö†Ô∏è **Hi·ªán t·∫°i:**

- `verify: false` - b·ªè qua SSL verification

‚úÖ **Production:**

- Enable SSL verification
- S·ª≠ d·ª•ng certificates
- Enable NiFi authentication (username/password ho·∫∑c certificates)

### 3. Airflow Connections

‚úÖ **Best practice:**

- L∆∞u sensitive data trong Airflow Connections (encrypted)
- KH√îNG hardcode credentials trong DAG code
- S·ª≠ d·ª•ng Kubernetes Secrets cho connections

---

## FAQ

**Q: DAG c√≥ th·ªÉ miss messages kh√¥ng?**

A: Kh√¥ng, nh·ªù Kafka consumer group v√† offset tracking:

- Kafka l∆∞u offset c·ªßa m·ªói message ƒë√£ consume
- N·∫øu Airflow restart, s·∫Ω ti·∫øp t·ª•c t·ª´ offset cu·ªëi c√πng
- `auto.offset.reset: latest` ch·ªâ √°p d·ª•ng cho first-time connection

**Q: DAG c√≥ x·ª≠ l√Ω messages theo th·ª© t·ª± kh√¥ng?**

A: Kh√¥ng ƒë·∫£m b·∫£o th·ª© t·ª± n·∫øu `max_active_runs > 1`:

- Nhi·ªÅu DAG runs c√≥ th·ªÉ ch·∫°y parallel
- ƒê·ªÉ ƒë·∫£m b·∫£o th·ª© t·ª±, set `max_active_runs=1`

**Q: L√†m sao ƒë·ªÉ replay/reprocess messages?**

A: Reset consumer group offset:

```bash
kafka-consumer-groups.sh \
  --bootstrap-server openhouse-kafka:9092 \
  --group airflow-csv-ingestion-consumer \
  --reset-offsets \
  --to-earliest \
  --topic csv-ingestion \
  --execute
```

**Q: NiFi process group ƒë√£ ch·∫°y r·ªìi, trigger l·∫°i c√≥ sao kh√¥ng?**

A: T√πy thu·ªôc NiFi configuration:

- N·∫øu processors ƒëang RUNNING, request c√≥ th·ªÉ ignored ho·∫∑c restart
- Best practice: Check state tr∆∞·ªõc khi trigger

---

## Next Steps

1. ‚úÖ C·∫•u h√¨nh connections v√† variables
2. ‚úÖ Deploy v√† test DAG
3. üìù Setup monitoring & alerting
4. üìù Configure backups cho Airflow metadata
5. üìù Implement data quality checks
6. üìù Add metrics dashboard (Grafana)

---

## References

- [Airflow Kafka Provider Documentation](https://airflow.apache.org/docs/apache-airflow-providers-apache-kafka/stable/index.html)
- [NiFi REST API Documentation](https://nifi.apache.org/docs/nifi-docs/rest-api/index.html)
- [Kafka SASL Authentication](https://kafka.apache.org/documentation/#security_sasl)
