# âš ï¸ PhÃ¢n tÃ­ch lá»—i: Airflow Spark Job Submission Failed

## ğŸ”´ Lá»–I HIá»†N Táº I

### Triá»‡u chá»©ng:

```
AirflowException: Pod taxi-ingestion-spark-submit-rzl7ndy6 returned a failure.
Status: Failed
Exit Code: 1
Reason: Error
Container: base (kubectl)
```

### Pod Details:

- **Image**: `bitnamilegacy/kubectl:1.33.4-debian-12-r0`
- **Command**: `kubectl apply -f /mnt/manifests/taxi-data-ingestion.yaml`
- **ServiceAccount**: `openhouse-spark-operator-spark`
- **Status**: Terminated with exit code 1

---

## ğŸ” NGUYÃŠN NHÃ‚N Gá»C Rá»„

### Problem: **RBAC Permission Denied** âŒ

#### Test RBAC:

```bash
kubectl auth can-i create sparkapplications \
  --all-namespaces \
  --as=system:serviceaccount:default:openhouse-spark-operator-spark

# Result: no âŒ
```

**ServiceAccount `openhouse-spark-operator-spark` KHÃ”NG cÃ³ quyá»n táº¡o SparkApplication resources!**

### Why This Happens:

1. **Airflow DAG sá»­ dá»¥ng KubernetesPodOperator** Ä‘á»ƒ submit Spark job
2. **Pod cháº¡y `kubectl apply`** vá»›i ServiceAccount `openhouse-spark-operator-spark`
3. **ServiceAccount nÃ y khÃ´ng cÃ³ ClusterRole/Role** Ä‘á»ƒ táº¡o SparkApplication CRD
4. **kubectl apply fails** vá»›i permission denied
5. **Pod returns exit code 1** â†’ Airflow task fails

## ğŸ”§ CÃCH FIX CHI TIáº¾T

### âš ï¸ LÆ¯U Ã QUAN TRá»ŒNG

**CÃ³ 2 ServiceAccounts cáº§n permissions:**

1. **`openhouse-spark-operator-spark`** - DÃ¹ng bá»Ÿi **KubernetesPodOperator** Ä‘á»ƒ submit Spark job (kubectl apply)
2. **`openhouse-airflow-worker`** - DÃ¹ng bá»Ÿi **SparkKubernetesSensor** trong worker pods Ä‘á»ƒ monitor Spark job

â†’ **Cáº¢ HAI Ä‘á»u cáº§n quyá»n truy cáº­p SparkApplication resources!**

---

### BÆ°á»›c 1: Táº¡o ClusterRole

ClusterRole Ä‘á»‹nh nghÄ©a permissions cáº§n thiáº¿t:

```bash
cd /mnt/d/data-platform/infra/k8s/orchestration

# Create rbac directory
mkdir -p rbac

# Create ClusterRole
cat > rbac/spark-submit-clusterrole.yaml <<'EOF'
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: spark-submit-role
  labels:
    app: airflow
    component: spark-submit
rules:
  # Permission to manage SparkApplications
  - apiGroups: ["sparkoperator.k8s.io"]
    resources: ["sparkapplications"]
    verbs: ["create", "get", "list", "watch", "update", "patch", "delete"]

  # Permission to get/list pods (for monitoring Spark driver/executor pods)
  - apiGroups: [""]
    resources: ["pods", "pods/log"]
    verbs: ["get", "list", "watch"]

  # Permission to get/list services (for Spark UI service)
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get", "list"]

  # Permission to get configmaps (if SparkApplication needs it)
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get", "list"]
EOF
```

---

### BÆ°á»›c 2: Táº¡o ClusterRoleBinding (CHO Cáº¢ 2 ServiceAccounts)

**QUAN TRá»ŒNG**: Add **Cáº¢ HAI** ServiceAccounts vÃ o subjects list:

```bash
# Create ClusterRoleBinding
cat > rbac/spark-submit-clusterrolebinding.yaml <<'EOF'
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: spark-submit-binding
  labels:
    app: airflow
    component: spark-submit
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: spark-submit-role
subjects:
  # ServiceAccount for submitting Spark jobs (KubernetesPodOperator)
  - kind: ServiceAccount
    name: openhouse-spark-operator-spark
    namespace: default
  # ServiceAccount for monitoring Spark jobs (SparkKubernetesSensor in worker pods)
  - kind: ServiceAccount
    name: openhouse-airflow-worker
    namespace: default
EOF
```

---

### BÆ°á»›c 3: Apply RBAC Resources

```bash
# Apply ClusterRole
kubectl apply -f rbac/spark-submit-clusterrole.yaml

# Apply ClusterRoleBinding
kubectl apply -f rbac/spark-submit-clusterrolebinding.yaml
```

**Output mong Ä‘á»£i:**

```
clusterrole.rbac.authorization.k8s.io/spark-submit-role created
clusterrolebinding.rbac.authorization.k8s.io/spark-submit-binding created
```

---

### BÆ°á»›c 4: Verify Permissions

**Test cáº£ HAI ServiceAccounts:**

```bash
# Test 1: Permissions cho submit job (openhouse-spark-operator-spark)
kubectl auth can-i create sparkapplications \
  --namespace=default \
  --as=system:serviceaccount:default:openhouse-spark-operator-spark

# Expected: yes âœ…

# Test 2: Permissions cho monitor job (openhouse-airflow-worker)
kubectl auth can-i get sparkapplications \
  --namespace=default \
  --as=system:serviceaccount:default:openhouse-airflow-worker

# Expected: yes âœ…
```

**View ClusterRoleBinding details:**

```bash
kubectl get clusterrolebinding spark-submit-binding -o yaml
```

Expected output sáº½ hiá»ƒn thá»‹ **2 subjects**:

```yaml
subjects:
  - kind: ServiceAccount
    name: openhouse-spark-operator-spark
    namespace: default
  - kind: ServiceAccount
    name: openhouse-airflow-worker
    namespace: default
```

---

### BÆ°á»›c 5: Re-run Airflow DAG

```bash
# Option 1: Trigger from Airflow UI
# 1. Truy cáº­p http://localhost:8080
# 2. Find DAG "taxi-data-ingestion-spark"
# 3. Click "Trigger DAG"
# 4. Monitor tasks:
#    - submit_taxi_ingestion_spark_job (should succeed)
#    - monitor_taxi_ingestion_spark_job (should succeed)

# Option 2: Trigger tá»« CLI (if airflow CLI available)
airflow dags trigger taxi-data-ingestion-spark
```

---

### BÆ°á»›c 6: Monitor Execution

#### 6.1 Check Submit Task Logs

```bash
# Get Airflow scheduler pod
SCHEDULER_POD=$(kubectl get pods -n default | grep scheduler | awk '{print $1}')

# View logs (or check from Airflow UI)
kubectl logs $SCHEDULER_POD -n default | grep -A 10 "submit_taxi_ingestion_spark_job"
```

**Success logs:**

```
sparkapplication.sparkoperator.k8s.io/taxi-data-ingestion created
```

#### 6.2 Check Monitor Task Logs

From Airflow UI â†’ DAG â†’ Task `monitor_taxi_ingestion_spark_job` â†’ Logs

**Success logs:**

```
INFO - Poking for Spark application taxi-data-ingestion
INFO - Application status: RUNNING
INFO - Application status: COMPLETED
INFO - Success criteria met. Exiting.
```

#### 6.3 Check SparkApplication Status

```bash
# List SparkApplications
kubectl get sparkapplications -n default

# Detailed status
kubectl describe sparkapplication taxi-data-ingestion -n default
```

**Expected statuses:**

- `SUBMITTING` â†’ `RUNNING` â†’ `COMPLETED` (success)
- Or `FAILED` if there's error in Spark job itself

---

## âœ… VERIFY SUCCESS

### Test 1: Check RBAC Applied

```bash
kubectl get clusterrole spark-submit-role
kubectl get clusterrolebinding spark-submit-binding

# Describe to see details
kubectl describe clusterrolebinding spark-submit-binding
```

### Test 2: Manual Test kubectl apply

```bash
# Create a test pod with same ServiceAccount
kubectl run test-spark-submit \
  --image=bitnamilegacy/kubectl:1.33.4-debian-12-r0 \
  --restart=Never \
  --serviceaccount=openhouse-spark-operator-spark \
  -n default \
  --command -- sleep 3600

# Exec into pod
kubectl exec -it test-spark-submit -n default -- bash

# Inside pod, test kubectl
kubectl auth can-i create sparkapplications
# Should return: yes

# Cleanup
exit
kubectl delete pod test-spark-submit -n default
```

### Test 3: Verify SparkApplication Created

```bash
# After running DAG task
kubectl get sparkapplications -n default

# Expected:
# NAME                   STATUS    ATTEMPTS   START                  FINISH   AGE
# taxi-data-ingestion   RUNNING   1          2025-12-26T00:xx:xx            30s
```

### Test 4: Check Airflow Task Logs

From Airflow UI:

1. Go to DAG `taxi-data-ingestion-spark`
2. Click on task `submit_taxi_ingestion_spark_job`
3. View logs

**Success logs should show:**

```
sparkapplication.sparkoperator.k8s.io/taxi-data-ingestion created
```

---

## ğŸ“Š TROUBLESHOOTING

### Issue: "still getting permission denied"

**Check**:

```bash
# Verify ClusterRoleBinding
kubectl get clusterrolebinding spark-submit-binding -o yaml

# Ensure subjects.name matches ServiceAccount
# Ensure subjects.namespace is "default"
```

**Fix**:

```bash
# Delete and recreate binding
kubectl delete clusterrolebinding spark-submit-binding
kubectl apply -f rbac/spark-submit-clusterrolebinding.yaml
```

### Issue: "ServiceAccount not found"

**Check**:

```bash
kubectl get serviceaccount openhouse-spark-operator-spark -n default
```

**If not exists**, check Spark Operator installation:

```bash
kubectl get pods -n spark-operator
kubectl get serviceaccount -A | grep spark
```

### Issue: "SparkApplication CRD not registered"

**Check**:

```bash
kubectl get crd | grep sparkapplication
```

**If not exists**, install Spark Operator:

```bash
helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
helm install spark-operator spark-operator/spark-operator -n spark-operator --create-namespace
```

### Issue: "SparkKubernetesSensor fails with 403 Forbidden"

**Lá»—i hiá»ƒn thá»‹:**

```
ApiException: (403)
Reason: Forbidden
User "system:serviceaccount:default:openhouse-airflow-worker" cannot get resource "sparkapplications"
```

**NguyÃªn nhÃ¢n**: ServiceAccount `openhouse-airflow-worker` khÃ´ng Ä‘Æ°á»£c add vÃ o ClusterRoleBinding

**Check**:

```bash
# Verify airflow-worker cÃ³ permissions chÆ°a
kubectl auth can-i get sparkapplications \
  --as=system:serviceaccount:default:openhouse-airflow-worker

# Náº¿u tráº£ vá» "no" â†’ cáº§n add vÃ o binding
```

**Fix**:

```bash
# View current ClusterRoleBinding
kubectl get clusterrolebinding spark-submit-binding -o yaml

# Náº¿u chá»‰ tháº¥y 1 subject, cáº§n add thÃªm airflow-worker:
kubectl edit clusterrolebinding spark-submit-binding

# ThÃªm vÃ o subjects list:
# subjects:
# - kind: ServiceAccount
#   name: openhouse-spark-operator-spark
#   namespace: default
# - kind: ServiceAccount
#   name: openhouse-airflow-worker    # â† ADD THIS
#   namespace: default

# Hoáº·c apply láº¡i file YAML Ä‘Ã£ sá»­a:
kubectl apply -f rbac/spark-submit-clusterrolebinding.yaml
```

**Verify fix**:

```bash
# Test láº¡i permission
kubectl auth can-i get sparkapplications \
  --as=system:serviceaccount:default:openhouse-airflow-worker
# Should return: yes

# Re-run DAG task monitor_taxi_ingestion_spark_job
# Should succeed now âœ…
```

## ğŸ“ TÃ“M Táº®T

**Váº¥n Ä‘á»**:

- âŒ ServiceAccount `openhouse-spark-operator-spark` khÃ´ng cÃ³ quyá»n **táº¡o** SparkApplication (submit task fails)
- âŒ ServiceAccount `openhouse-airflow-worker` khÃ´ng cÃ³ quyá»n **Ä‘á»c** SparkApplication (monitor task fails)

**Giáº£i phÃ¡p**: Táº¡o ClusterRole + ClusterRoleBinding cho **Cáº¢ HAI** ServiceAccounts

**3 bÆ°á»›c FIX nhanh**:

1. âœ… **Táº¡o ClusterRole** vá»›i permissions cho SparkApplication
2. âœ… **Táº¡o ClusterRoleBinding** add Cáº¢ 2 ServiceAccounts vÃ o subjects
3. âœ… **Verify cáº£ 2**:

   ```bash
   # Submit permissions
   kubectl auth can-i create sparkapplications \
     --as=system:serviceaccount:default:openhouse-spark-operator-spark

   # Monitor permissions
   kubectl auth can-i get sparkapplications \
     --as=system:serviceaccount:default:openhouse-airflow-worker
   ```

**Káº¿t quáº£ mong Ä‘á»£i**: Cáº£ 2 Ä‘á»u tráº£ vá» `yes` âœ…

**Files Ä‘Ã£ táº¡o**:

- `infra/k8s/orchestration/rbac/spark-submit-clusterrole.yaml`
- `infra/k8s/orchestration/rbac/spark-submit-clusterrolebinding.yaml`

Sau khi fix, re-run Airflow DAG sáº½ thÃ nh cÃ´ng cho cáº£ 2 tasks:

- âœ… `submit_taxi_ingestion_spark_job` - SparkApplication created
- âœ… `monitor_taxi_ingestion_spark_job` - SparkApplication monitored
